{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NySdSEezmV6",
        "outputId": "9dcfef03-aec4-49fe-b367-58dc42f7c696"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKhaKLkulPQH",
        "outputId": "97a98e55-9d36-4716-a36e-28e22f5b0ba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1GjyX6hhmkv3p8CkgvOoSe14VWUuNEGQI/07_PJT_final_01/01_clothes_classification\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/07_PJT_final_01/01_clothes_classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nJiL5kTnmS9_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten,Dense,Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qvV26wQQmjK-"
      },
      "outputs": [],
      "source": [
        "img_size = 224\n",
        "channel=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqwL6gmsmjNv",
        "outputId": "b8090d66-d07f-4843-d208-cd87b438687a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 14341 images belonging to 4 classes.\n",
            "Found 7894 images belonging to 4 classes.\n",
            "Found 10 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator( \n",
        "        rescale=1./255,         # 픽셀 값을 0~1 범위로 변환\n",
        "        # rotation_range=40,      # 40도까지 회전\n",
        "        # width_shift_range=0.2,  # 20%까지 좌우 이동\n",
        "        # height_shift_range=0.2, # 20%까지 상하 이동\n",
        "        # shear_range=0.2,        # 20%까지 기울임\n",
        "        # zoom_range=0.2,         # 20%까지 확대\n",
        "        # horizontal_flip=True,   # 좌우 뒤집기\n",
        "    )\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    './dataset/Train',\n",
        "    batch_size=100,      \n",
        "    class_mode='categorical', \n",
        "    target_size=(img_size, img_size)) \n",
        "valid_datagen = ImageDataGenerator(rescale=1./255) # 스케일링만 진행\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    './dataset/Validation',\n",
        "    batch_size=80,      \n",
        "    class_mode='categorical', \n",
        "    target_size=(img_size, img_size))\n",
        "test_datagen = ImageDataGenerator(rescale=1./255) # 스케일링만 진행\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    './dataset/data/test',\n",
        "    batch_size=10,      \n",
        "    class_mode='categorical', \n",
        "    target_size=(img_size, img_size),\n",
        "    shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxwBkpkjmjP4",
        "outputId": "4c7edede-57e2-43d2-f42c-43189109bab0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_generator class :  {'bottoms': 0, 'one-piece': 1, 'outerwear': 2, 'tops': 3}\n",
            "valid_generator class :  {'bottoms': 0, 'one-piece': 1, 'outerwear': 2, 'tops': 3}\n",
            "test_generator class :  {'bottoms': 0, 'one-piece': 1, 'outerwear': 2, 'tops': 3}\n"
          ]
        }
      ],
      "source": [
        "print('train_generator class : ', train_generator.class_indices)\n",
        "print('valid_generator class : ', valid_generator.class_indices)\n",
        "print('test_generator class : ', test_generator.class_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnP3O4NFknJj"
      },
      "source": [
        "## 모델 학습하기_VGG16\n",
        "- 가중치 imagenet 사용\n",
        "- 입력 데이터 사이즈 (224,224,3)\n",
        "- 옵티마이저 adam, 학습률 0.0001\n",
        "- train 데이터 배치사이즈 100\n",
        "- 콜백함수 EarlyStopping, ModelCheckpoint\n",
        "- 출력층\n",
        "   * Dense(4, activation='softmax')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mfEsc9mWmjTZ"
      },
      "outputs": [],
      "source": [
        "# 파라미터 설정\n",
        "classes = len(train_generator.class_indices)\n",
        "epochs = 200\n",
        "batch_size = 96"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzWBNwdRmjV0",
        "outputId": "d0cd67ce-8495-4c3f-c124-dadfb37bc1fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n",
            "58900480/58889256 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "vgg16 = tf.keras.applications.VGG16(weights='imagenet',\n",
        "                                    include_top=False, \n",
        "                                    input_shape=(224, 224, 3))\n",
        "vgg16.trainable = False # 학습으로 기존 가중치 갱신을 하지 않도록 지정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSjVTRrCmjaS",
        "outputId": "894432a5-ac22-4c02-cbdd-925f2039240a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               3211392   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,926,596\n",
            "Trainable params: 3,211,908\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(vgg16)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MO-2xfRRmyCW"
      },
      "outputs": [],
      "source": [
        "# 모델 환경설정\n",
        "model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6VCks1ZtmyEr"
      },
      "outputs": [],
      "source": [
        "model_name = './model/VGG16_01_{epoch:02d}-{val_loss:.4f}.hdf5'\n",
        "checkpointer = ModelCheckpoint(filepath=model_name, monitor='val_loss',save_best_only=True) # 성능이 개선될떄만 저장하도록\n",
        "earlystopping = EarlyStopping(monitor='val_loss', patience=5) # 5번동안 성능개선이 없으면 학습 조기종료"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUXu-pAAmyI3"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_generator,\n",
        "                    epochs=100,\n",
        "                    validation_data=valid_generator, \n",
        "                    callbacks = [[earlystopping, checkpointer]]) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFn5PPTVm-V5"
      },
      "source": [
        "## 모델 저장 및 불러오기\n",
        "- model.save()\n",
        "  - 학습결과를 저장하기 위한 함수 모델형태(architecture)와 파라미터를 저장\n",
        "  - 모델 학습 중간 과정 저장을 통해 최선의 결과 모델을 선택\n",
        "  - 만들어진 모델을 다른 사람들과 공유함으로서 학습 재연성 향상"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "NS7I1dy1myLU",
        "outputId": "8a59f82c-95cf-452b-a41c-6abe8164c768"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-d5412d791866>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    TheModelClass() # model과 같은 모델 형태의 객체\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "model.state_dict() # 모델의 파라미터를 표시\n",
        "torch.save(model.state_dict(), os.path.join(MODEL_PATH, \"model.pt\") # 모델 파라미터 저장\n",
        "\n",
        "new_model = TheModelClass() # model과 같은 모델 형태의 객체\n",
        "\n",
        "# 같은 모델의 형태에서 파라미터만 불러옴\n",
        "new_model.load_state_dict(torch.load(os.path.join(MODEL_PATH, \"model.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "YDBA4B1qpRnM",
        "outputId": "3aba3408-4dfa-47de-a684-9077b8cb55fa"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-779eb4097c43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 모델의 architecture와 함께 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 모델의 architecture와 함께 불러옴\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "torch.save(model, os.path.join(MODEL_PATH, \"model.pt\")) # 모델의 architecture와 함께 저장\n",
        "model = torch.load(os.path.join(MODEL_PATH, \"model.pt\")) # 모델의 architecture와 함께 불러옴"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "E1uf16HYmTAl",
        "outputId": "5c1928cc-38b8-49e7-9e22-857721d00c39"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-7d3522886f6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# checkpoint dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 모델 파라미터 불러옴\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# optimizer 파라미터 불러옴\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "checkpoint = torch.load(PATH) # checkpoint dictionary\n",
        "model.load_state_dict(checkpoint['model_state_dict']) # 모델 파라미터 불러옴\n",
        "\n",
        "# optimizer 파라미터 불러옴\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict']) \n",
        "epoch = checkpoint['epoch'] \n",
        "loss = checkpoint['loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAyWIktxmTDK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DbElZFC5mTE_"
      },
      "outputs": [],
      "source": [
        "# 모델 저장\n",
        "# accuracy = round(max(history.history['accuracy'])*100,0)\n",
        "model.save(f'/content/drive/MyDrive/07_PJT_final_01/01_clothes_classification/model/VGG16_01_11-17.2763.h5') # 최종 모델 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "id": "X84-CQtGmTGn",
        "outputId": "b317d5f7-8e64-4567-e74a-f2e1b0d99680"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-e79158451c2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 만들어진 모델에 대해 train dataset과 validation dataset의 loss 를 그래프로 표현해 봅니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1152x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(16,5))\n",
        "\n",
        "# 만들어진 모델에 대해 train dataset과 validation dataset의 loss 를 그래프로 표현해 봅니다.\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc=0)\n",
        "\n",
        "# 만들어진 모델에 대해 train dataset과 validation dataset의 accuracy 를 그래프로 표현해 봅니다.\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqhxDFcdmTIe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hF5quLTrmTMC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "PJT03_VGG16_03.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
